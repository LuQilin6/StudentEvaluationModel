{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Professor Evaluation to Find Corresponding Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:52:57.429895Z",
     "start_time": "2024-08-30T04:52:57.160862Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:10:29.559055Z",
     "start_time": "2024-08-21T20:10:29.462206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to extract subtables based on a condition (e.g., a specific marker or blank rows)\n",
    "def extract_subtables(df):\n",
    "    subtables = []\n",
    "    subtable = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row.isnull().all():\n",
    "            if subtable:\n",
    "                subtables.append(pd.DataFrame(subtable))\n",
    "                subtable = []\n",
    "        else:\n",
    "            subtable.append(row)\n",
    "    if subtable:\n",
    "        subtables.append(pd.DataFrame(subtable))\n",
    "    return subtables\n",
    "def extract_student_application_ID(df):\n",
    "    print(\"read student application ID\")\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    name_app_id_dict = df.set_index('Name')['Application ID'].to_dict()\n",
    "    return name_app_id_dict\n",
    "\n",
    "# extract student information from each round \n",
    "def extract_tables(roundNum):\n",
    "    file_path = f'YOUR_STUDENT_DATA.xlsx' #replace with real data\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Display the sheet names\n",
    "    print(xls.sheet_names)\n",
    "\n",
    "    # Read each sheet into a DataFrame\n",
    "    data = {}\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        data[sheet_name] = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    # Extract subtables from each sheet\n",
    "    subtables_dict = {}\n",
    "    for sheet_name, df in data.items():\n",
    "        subtables_dict[sheet_name] = df\n",
    "\n",
    "    # Display subtables\n",
    "    df = []\n",
    "\n",
    "    for sheet_name, subtables in subtables_dict.items():\n",
    "        print(f\"\\nSheet: {sheet_name}\")\n",
    "        # if \"result\" in sheet_name:\n",
    "        #     temp_dict = extract_student_application_ID(subtables)\n",
    "        # elif \"detail\" in sheet_name:\n",
    "\n",
    "        if \"result\" in sheet_name:\n",
    "            temp_dict = extract_student_application_ID(subtables)\n",
    "            student_ID_list.update(temp_dict)\n",
    "\n",
    "\n",
    "        if \"original\" in sheet_name or \"details\" in sheet_name:\n",
    "            subDF = subtables\n",
    "            primary_columns = subDF.columns\n",
    "            secondary_columns = subDF.iloc[0]\n",
    "\n",
    "            # Combine them, using the secondary name if the primary is None\n",
    "            columns = [\n",
    "                primary if \"Unnamed\" not in str(primary) else secondary\n",
    "                for primary, secondary in zip(primary_columns, secondary_columns)\n",
    "            ]\n",
    "\n",
    "            # Set the new columns to the DataFrame and drop the first two rows\n",
    "            subDF.columns = columns\n",
    "\n",
    "            subDF = subDF.drop([0])\n",
    "\n",
    "            # Reset index\n",
    "            subDF = subDF.reset_index(drop=True)\n",
    "            subDF = subDF.dropna(subset=['最终得分'])\n",
    "            subDF = subDF.ffill()\n",
    "            subDF = subDF.reset_index(drop=True)\n",
    "            # print(subDF.columns)\n",
    "            # Initialize lists to store the structured data\n",
    "            mapping = {\n",
    "                '学生': 'name',\n",
    "                '申请号': 'id',\n",
    "                '邮箱': None,  # Not needed in the provided mapping\n",
    "                '主席决策': None,  # Not needed in the provided mapping\n",
    "                '委员会推荐': None,\n",
    "                '分委会推荐': None,\n",
    "                '教授评分': \"recommend score\",  # in r7,8\n",
    "                # '教授评分': None, # in r10\n",
    "                '教授推荐汇总': None,  # Not needed in the provided mapping\n",
    "                '分数': \"score\",  # Not needed in the provided mapping\n",
    "                '教授': \"professor\",  # Not needed in the provided mapping\n",
    "                '科目': 'major',\n",
    "                'GPA': 'gpa',\n",
    "                '数学能力': 'math ability',\n",
    "                '语言文字综合能力': 'mastery of language',\n",
    "                '主题核心课程成绩': 'specialty core courses',\n",
    "                '实验课成绩': 'lab courses',\n",
    "                '毕业设计/作品及成绩': 'capstone/design project',\n",
    "                '企业/临床实习成绩': 'internship',\n",
    "                '社会服务活动': 'community service',\n",
    "                '学生社团活动': 'student clubs',\n",
    "                '国内国际大赛成绩': 'major int\\'l/national competition',\n",
    "                '本科毕业院校': 'college of bachelor degree',\n",
    "                '最终得分': \"overall score\"  # Not needed in the provided mapping\n",
    "            }\n",
    "            # filtered_mapping = {k: v for k, v in mapping.items() if v is not None}\n",
    "            subDF.rename(columns=mapping, inplace=True)\n",
    "            subDF = subDF.drop(columns=[None])\n",
    "            df.append(subDF)\n",
    "            print(\"Length of sub table: \"+str(len(subDF)))\n",
    "\n",
    "    #merge sub dataframe into one dataframe        \n",
    "    df=pd.concat(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:02:29.676294Z",
     "start_time": "2024-08-21T21:02:28.904295Z"
    }
   },
   "outputs": [],
   "source": [
    "student_ID_list={}\n",
    "table7=extract_tables(7)\n",
    "table8=extract_tables(8)\n",
    "table10=extract_tables(10)\n",
    "\n",
    "#unify the id in each table\n",
    "table7['id'] = table7['name'].map(student_ID_list)\n",
    "for id in table8['id']:\n",
    "    newID = id[:11]\n",
    "    table8.loc[table8['id'] == id, 'id'] = newID\n",
    "for id in table10['id']:\n",
    "    newID = int(id)\n",
    "    table10.loc[table10['id'] == id, 'id'] = newID    \n",
    "    \n",
    "df=pd.concat([table7, table8, table10])\n",
    "df=df.reset_index(drop=True)\n",
    "df['id']=pd.to_numeric(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T20:09:00.924951Z",
     "start_time": "2024-08-21T20:09:00.840415Z"
    }
   },
   "outputs": [],
   "source": [
    "#match name with id if id is not in the sheet\n",
    "# df['id'] = df['id'].fillna(df['name'].map(student_ID_list))\n",
    "# df['id']=pd.to_numeric(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:04:12.211494Z",
     "start_time": "2024-08-21T21:04:12.120079Z"
    }
   },
   "outputs": [],
   "source": [
    "#map the recommend score\n",
    "recommmend_score_mapping = {\n",
    "    '强烈推荐': 2,\n",
    "    '推荐': 1,\n",
    "    '居中': 0,\n",
    "    '不推荐': -1\n",
    "}\n",
    "\n",
    "df['recommend score']=df['recommend score'].map(recommmend_score_mapping)\n",
    "df['score']=df.groupby('id')['recommend score'].transform('sum')\n",
    "df.drop('recommend score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Mean and STD of Professor's Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:18:02.199994Z",
     "start_time": "2024-08-21T21:18:01.272791Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "results = pd.DataFrame()\n",
    "\n",
    "def mean_ignore_zeros(x):\n",
    "    return x[x != 0].mean()\n",
    "\n",
    "# Custom function to calculate std ignoring zeros\n",
    "def std_ignore_zeros(x):\n",
    "    # print(x[x == 0].sum())\n",
    "    return x[x != 0].std()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    grouped = df.groupby('id')[col].agg(mean_ignore_zeros).rename(f'{col}_mean')\n",
    "    grouped_std = df.groupby('id')[col].agg(std_ignore_zeros).rename(f'{col}_std')\n",
    "    \n",
    "    if results.empty:\n",
    "        results = grouped.to_frame().join(grouped_std)\n",
    "    else:\n",
    "        results = results.join(grouped.to_frame()).join(grouped_std)\n",
    "results = results.reset_index()\n",
    "\n",
    "std_columns = [i for i in results.columns if \"std\" in i]\n",
    "mean_columns = [i for i in results.columns if \"mean\" in i]\n",
    "print(results[mean_columns].mean())\n",
    "results[std_columns] = results[std_columns]**2\n",
    "sqrt_mean_square = np.sqrt(results[std_columns].mean())\n",
    "print(sqrt_mean_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Student Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:19:32.157398Z",
     "start_time": "2024-08-21T21:19:32.069597Z"
    }
   },
   "outputs": [],
   "source": [
    "not_find_list = []\n",
    "find_list=[]\n",
    "def read_files_with_id_in_folder(folder_path, ID):\n",
    "    # Iterate through all files in the specified folder\n",
    "    profile = None\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Construct absolute path to file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if the current path is a file and not a directory\n",
    "        if os.path.isfile(file_path) and \".pdf\" in file_path and str(ID) in file_path:\n",
    "            print(f\"Found file: {filename}\")\n",
    "            profile = extract_student_profile(file_path)\n",
    "            profile[\"Proposed Research Plan / Vision Statement\"] = profile[\"Proposed Research Plan / Vision Statement\"][:10000]\n",
    "            profile[\"/ CV\"] = profile[\"/ CV\"][:4000]\n",
    "            if len(json.dumps(profile)) > 20000:\n",
    "                print(f\"warning: {filename}, string len: {len(json.dumps(profile))}\")\n",
    "            # profile\n",
    "            # If you need to read the file, you can open it here\n",
    "            # with open(file_path, 'r') as file:\n",
    "            #     content = file.read()\n",
    "            #     # Do something with the content\n",
    "            #     print(content)\n",
    "    if not profile:\n",
    "        print(f\"Not find {ID}\")\n",
    "        not_find_list.append(ID)\n",
    "    return profile\n",
    "\n",
    "def check_files_existence_with_id(folder_path, ID):\n",
    "    # Iterate through all files in the specified folder\n",
    "    check=False\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Construct absolute path to file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if the current path is a file and not a directory\n",
    "        if os.path.isfile(file_path) and \".pdf\" in file_path and str(ID) in file_path:\n",
    "            check=True\n",
    "            find_list.append(ID)\n",
    "    if not check:\n",
    "        print(f\"Not find {ID}\")\n",
    "        not_find_list.append(ID)\n",
    "    return find_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:23:13.868898Z",
     "start_time": "2024-08-09T15:23:13.721128Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"STUDENT_PROFILE_PATH\"\n",
    "def rename_files(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the filename contains a dot\n",
    "        new_name = filename.replace('.pdf', '').replace('pdf', '')\n",
    "        print(new_name)\n",
    "        if '.' in new_name:\n",
    "            # Get the new filename\n",
    "            new_name = \"\".join(filename.split(\".\")[1])\n",
    "        if '_' in new_name:\n",
    "            new_name = filename.split(\"_\")[0]\n",
    "        new_name = new_name[:11] + \".pdf\"\n",
    "        # Full old and new file paths\n",
    "        old_file = os.path.join(folder_path, filename)\n",
    "        new_file = os.path.join(folder_path, new_name)\n",
    "        # Rename the file\n",
    "        try:\n",
    "            os.rename(old_file, new_file)\n",
    "        except:\n",
    "            print(new_file + \"   exist\")\n",
    "        print(f'Renamed: {filename} to {new_name}')\n",
    "\n",
    "# Call the function\n",
    "# rename_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File From Raw PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:24:11.880985Z",
     "start_time": "2024-08-09T15:24:11.756957Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"STUDENT_PROFILE_PATH\"\n",
    "read_file_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:46:42.664452Z",
     "start_time": "2024-08-09T15:25:19.197024Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, row in results.iterrows():\n",
    "    row_id = int(row['id'])\n",
    "    profile = read_files_with_id_in_folder(path, row_id)\n",
    "    read_file_list.append(profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:48:35.051705Z",
     "start_time": "2024-08-09T15:48:34.864043Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert read list to json\n",
    "\n",
    "student_info_path = \"Processed_STUDENT_PROFILE_PATH\"\n",
    "important_keys = [\"Education Background\", \"Awards and Professional Qualifications\",\n",
    "                  \"Publications\", \"English Language Proficiency\", \"Proposed Research Plan / Vision Statement\",\n",
    "                  \"/ CV\", \"Extracurricular Activities / Volunteer Work\", \"Taken Courses\"]\n",
    "for profile in tqdm(read_file_list):\n",
    "    ID = profile[\"ID\"]\n",
    "    filtered_profile = {key: profile[key] for key in important_keys}\n",
    "    if not os.path.exists(student_info_path):\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(student_info_path)\n",
    "    with open(f'{student_info_path}\\\\{ID[\"identity\"][1]}.json', 'w') as fp:\n",
    "        json.dump(profile, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:21:00.621255Z",
     "start_time": "2024-08-21T21:20:59.514617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all missing student id/name\n",
    "\n",
    "path = \"STUDENT_PROFILE_PATH\"\n",
    "read_file_list = []\n",
    "for i, row in results.iterrows():\n",
    "    row_id = int(row['id'])\n",
    "    exist_file_list = check_files_existence_with_id(path, row_id)\n",
    "    #read_file_list.append(profile)\n",
    "\n",
    "str_not_find_list=[str(i) for i in not_find_list]\n",
    "missing_student_file=df.loc[df['id'].isin(str_not_find_list)]\n",
    "missing_student_file.drop_duplicates(subset=['id'],inplace=True)\n",
    "missing_student_file=missing_student_file.loc[:,['name','id']]\n",
    "missing_student_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File From Existing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:47:15.532466Z",
     "start_time": "2024-08-21T18:47:15.437440Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"STUDENT_PROFILE_PATH\"\n",
    "read_path = \"Processed_STUDENT_PROFILE_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_num=0\n",
    "# for filename in os.listdir(read_path):\n",
    "#     file_path = os.path.join(read_path, filename)\n",
    "#     if os.path.isfile(file_path) and \".json\" in file_path:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "#         if len(data[\"Awards and Professional Qualifications\"])==0:\n",
    "#             missing_num+=1\n",
    "#             print(data[\"ID\"])\n",
    "# print(missing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:47:30.704177Z",
     "start_time": "2024-08-21T18:47:30.015392Z"
    }
   },
   "outputs": [],
   "source": [
    "read_file_list = []\n",
    "\n",
    "for filename in os.listdir(read_path):\n",
    "    file_path = os.path.join(read_path, filename)\n",
    "    if os.path.isfile(file_path) and \".json\" in file_path:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        if 'response' in data:\n",
    "            del data['response']\n",
    "        read_file_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T05:12:59.416091Z",
     "start_time": "2024-08-30T05:12:59.246206Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#enter you gpt related information here\n",
    "url = \"\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"\"\n",
    "}\n",
    "\n",
    "new_data = []\n",
    "\n",
    "def request_test():\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"you are a test\"},\n",
    "                     {\"role\": \"user\", \"content\": \"Write a test\"}],\n",
    "        # \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data)).json()\n",
    "    time.sleep(3)\n",
    "    return response\n",
    "\n",
    "\n",
    "def request(system_prompt, profile):\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": json.dumps(profile)}],\n",
    "        # \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data)).json()\n",
    "        #print(len(data[\"messages\"][0][\"content\"])+len(data[\"messages\"][1][\"content\"]))\n",
    "        response = response['choices'][0]['message']['content']\n",
    "        time.sleep(3)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\"You are a professor and interviewer who reviews the application of Master of Philosophy in Top-tier university, \\\n",
    "                and you are expected to analyze the applicants background in critical ways, be aware that you should use your background information on evaluating the school, award, publication, and company reputation. \\\n",
    "                Overall, you should analyze the background in following steps: \\\n",
    "                1. Categorized them into one of the following majors: Science, Engineering, Liberal Arts, Arts, Design, Business, Management, Medical \\\n",
    "                2. Rate the Student into the following criteria from 1 to 100, including: GPA, Math Ability, Mastery of Language, Specialty core courses, Lab courses, Capstone/Design project \\\n",
    "                , Internship, Community service, Student clubs, Major Int'l/National Competition, College of Bachelor Degree, College of higher degree. The rate range from 60 to 70 is very poor. 70 to 80 is normal. 80 to 90 is great. Above 90 is very outstanding. For most of the time, you should not give above 95 or below 60 unless the student did very well or very poor.\\\n",
    "                In GPA, normally 3.3/4.0, which is equivalent to 4.125/5.0, are consider fair gpa, which should be rated above 80. GPA below 3.0/4.0, which is equivalent to 3.75/5.0, should be below 75. Higher rank school, based on QS World University Rankings instead of reputation, can accept relative low GPA, and vice versa. You should focus more of the student's GPA during Bachelor's degree instead of the GPA during Master's degree. \\\n",
    "                In Mastery of Language, the full score of IELTS is 9.0, full score of TOEFL is 120, and full score of Duolingo is 160. 6.5/9.0 in IELTS, 90/120 in TOEFL, and 110/160 in Duolingo is consider a fair grade and you can give above 80. You should rate based on the overall score instead of the subject score in TOEFL, IELTS, or Duolingo. \\\n",
    "                In Math Ability, Specialty core Courses, and Lab courses, you should not only consider what course the student completed but also what grade the student got in that course. You need to read the student's grade from the \\\"Taken Courses\\\" based on the chart's format, like course, credit, grade. If the student have a low grade, below B- or 80/100, in multiple courses, you should give a low grade. Higher rank school, based on QS World University Rankings instead of reputation, can accept relative low grade, and vice versa.\\\n",
    "                In Capstone/Design project, you should be critical on Proposed Research Plan / Vision Statement, and the project the students did, most student writing seemingly meaningful research, while as professor you should verify if it is the real research problem. Unless the project is significant impactful, insightful or novel, you should not give score higher than 85. For a normal project, it should be around 75. You should not rate the project based on the score the student tell you. \\\n",
    "                In Award, be aware that the Mathematical Contest in Modeling is worth nothing only if it is the first price. For competition, National award could consider as high score. Otherwise, you should be critical in evaluating if the award is good or not.\\\n",
    "                ONLY in \\\"Community service\\\", you could give 70 if the student did not provide any information. For any other categories that the student did not provide information, you need to give NA/100. \\\n",
    "                In College of Bachelor Degree and College of higher degree, you need to compare the student's college's rank, categories it into one of the tier, and rate according to the score in the parenthesis.\\\n",
    "                Tier 1 college(above 90 points): Sun Yat-Sen University, Tianjin University, etc. Tier 2 college(80-90 points): South China University of Technology, Nanchang University, etc. Tier 3 college(below 80 points): Hainan University, Hangzhou Normal University, etc.  \\\n",
    "                The mean of the rating is 75, and the standard deviation is 11, you should differentiate the student to make sure the pass or fail is clear.\\\n",
    "                3. Write a short summary about the evaluation on student\\n\\n \\\n",
    "                4. Calculate the Overall Score for student based on previous score you give to that student. You should take the completeness of the student information into account, missing too many essential information will lead to score deduction in overall score. You must give an overall score. \\\n",
    "                5. Determine if the student could pass or not, the pass rate is 65%.\\\n",
    "                You should strictly follow the template rule for the response: \\\n",
    "                1. The score must be in front of the description e.g. GPA: 70/100 (original gpa 3.0/4.0)\\\n",
    "                2. Even you infer student ability you should include the inferring process in () e.g. Math Ability: 70/100 (Given the range of engineering and energy-related courses)\\\n",
    "                The following are the response example: \\\n",
    "                1. Major: Engineering (Industrial Engineering) \\\n",
    "                2. Rating: \\\n",
    "                  - GPA: 85/100 (Final GPA of 3.72/4.0 from New Jersey Institute of Technology)\\\n",
    "                  - Mastery of Language: 81/100 (IELTS score of 7.0)\\\n",
    "                  - Math Ability: 81/100 (Complete courses like Advanced Engineering Statistic with score of 80) \\\n",
    "                  - Specialty core courses: 88/100 (Courses like Advanced Engineering Statistics with score of A- indicate great specialization)\\\n",
    "                  - Lab courses: 75/100 (Participation in lab courses like Fundamentals Physics Experiment with score above 70) \\\n",
    "                  - Capstone/Design project: 75/100 (Research projects and publications) \\\n",
    "                  - Internship: 70/100 (Internship experiences at Tencent Interactive Entertainment) \\\n",
    "                  - Community service: 80/100 (Participation in University Art Troupe) \\\n",
    "                  - Student clubs: 70/100 (No information provided) \\\n",
    "                  - Major Int'l/National Competition: 80/100 (Third place in Mock Trading Contest) \\\n",
    "                  - College of Bachelor Degree: 84/100 (New Jersey Institute of Technology) \\\n",
    "                  - College of higher degree: 75/100 (University of Southampton) \\\n",
    "                3. Summary: \\\n",
    "                  XXXXXX \\\n",
    "                4. Overall Score: 78 \\\n",
    "                5. Passed or Unpassed: Unpassed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T17:29:15.423730Z",
     "start_time": "2024-08-30T17:29:00.867877Z"
    }
   },
   "outputs": [],
   "source": [
    "request_test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:51:28.516922Z",
     "start_time": "2024-08-21T18:51:28.429907Z"
    }
   },
   "outputs": [],
   "source": [
    "important_keys = [\"Education Background\", \"Awards and Professional Qualifications\",\n",
    "                  \"Publications\", \"English Language Proficiency\", \"Proposed Research Plan / Vision Statement\",\n",
    "                  \"/ CV\", \"Extracurricular Activities / Volunteer Work\", \"Taken Courses\"]\n",
    "save_path = f\"{path}\\\\Result_v12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:06:31.337388Z",
     "start_time": "2024-08-09T16:39:51.096521Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for profile in tqdm(read_file_list):\n",
    "    ID = profile[\"ID\"]\n",
    "    filtered_profile = {key: profile[key] for key in important_keys}\n",
    "    response = request(system_prompt,filtered_profile)\n",
    "    profile[\"response\"] = response\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(save_path)\n",
    "    with open(f'{save_path}\\\\{ID[\"identity\"][1]}.json', 'w') as fp:\n",
    "        json.dump(profile, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:06:47.042895Z",
     "start_time": "2024-08-09T17:06:46.918187Z"
    }
   },
   "outputs": [],
   "source": [
    "def rerunEmptyResponse(fileID):\n",
    "    profile=None\n",
    "    file_path = os.path.join(read_path, f\"{fileID}.json\")\n",
    "    if os.path.isfile(file_path) and \".json\" in file_path:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        if 'response' in data:\n",
    "            del data['response']\n",
    "        profile=data\n",
    "    \n",
    "    if profile is not None:\n",
    "        ID = profile[\"ID\"]\n",
    "        filtered_profile = {key: profile[key] for key in important_keys}\n",
    "        print(filtered_profile)\n",
    "        response = request(system_prompt,filtered_profile)\n",
    "        profile[\"response\"] = response\n",
    "        if not os.path.exists(save_path):\n",
    "            # Create a new directory because it does not exist\n",
    "            os.makedirs(save_path)\n",
    "        with open(f'{save_path}\\\\{ID[\"identity\"][1]}.json', 'w') as fp:\n",
    "            json.dump(profile, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:06:52.649218Z",
     "start_time": "2024-08-09T17:06:52.555497Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def decompose_response(response):\n",
    "    response = response.replace(\"**\", \"\").replace(\"-\", \"\")\n",
    "    sections = response.strip().split('\\n\\n')\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    major = None\n",
    "    ratings = {}\n",
    "    summary = None\n",
    "\n",
    "    \n",
    "    colon_type = \":\"\n",
    "    # Loop through each line and extract data\n",
    "    for section in sections:\n",
    "        lines = section.strip().split('\\n')\n",
    "        if 'Major' in lines[0]:\n",
    "            major = lines[0].split(colon_type)[1].strip().split('(')[0]\n",
    "        if 'Rating' in lines[0]:\n",
    "            for line in lines[1:]:\n",
    "                category, score_and_des = line.split(colon_type)[0], \"\".join(line.split(colon_type)[1:])\n",
    "                category = category.strip().lower()\n",
    "                score = score_and_des.split('(')[0].strip().split('/')[0][-2:]\n",
    "                try:\n",
    "                    description = score_and_des.split('(')[1].split(')')[0]\n",
    "                except:\n",
    "                    description = \"\"\n",
    "                try:\n",
    "                    score = float(score)\n",
    "                except ValueError:\n",
    "                    score = -1\n",
    "                ratings[category] = score\n",
    "                ratings[category + \"_description\"] = description\n",
    "        elif 'Summary' in lines[0]:\n",
    "            summary = ' '.join(lines[1:]).strip()\n",
    "        elif 'Overall Score' in lines[0]:\n",
    "            line = lines[0]\n",
    "            category, score_and_des = line.split(colon_type)[0], \"\".join(line.split(colon_type)[1:])\n",
    "            score = score_and_des.split('(')[0].strip().split('/')[0].strip()\n",
    "            try:\n",
    "                description = score_and_des.split('(')[1].split(')')[0]\n",
    "            except:\n",
    "                description = \"\"\n",
    "            try:\n",
    "                score = float(score)\n",
    "            except ValueError:\n",
    "                score = -1\n",
    "            ratings[\"llm pred score\"] = score\n",
    "        elif 'Passed or Unpassed' in lines[0]:\n",
    "            line = lines[0]\n",
    "            ratings[\"llm pred pass\"] = line.split(colon_type)[1].split('(')[0].strip() == \"Passed\"\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(ratings, index=[0])\n",
    "\n",
    "    # Add Major column\n",
    "    df['Major'] = major\n",
    "    df[\"Summary\"] = summary\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:06:54.607342Z",
     "start_time": "2024-08-09T17:06:54.514728Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def decompose_response_re(response):\n",
    "    # Initialize lists to store data\n",
    "    major = None\n",
    "    ratings = {}\n",
    "    summary = None\n",
    "\n",
    "    # Define regular expressions\n",
    "    major_regex = re.compile(r'Major:\\s*(.*?)(?:\\(|$)')\n",
    "    rating_regex = re.compile(r'\\*\\*\\s*(.*?)(?::|:\\*\\*):\\s*(\\d+/\\d+|\\d+|N/A)\\s*(?:\\((.*?)\\))?')\n",
    "    summary_regex = re.compile(r'Summary:\\n([\\s\\S]*)')\n",
    "\n",
    "    # Extract major\n",
    "    major_match = major_regex.search(response)\n",
    "    if major_match:\n",
    "        major = major_match.group(1).strip()\n",
    "\n",
    "    # Extract ratings\n",
    "    rating_section = re.search(r'Rating:\\s*([\\s\\S]+?)\\n\\n', response)\n",
    "    if rating_section:\n",
    "        for match in rating_regex.finditer(rating_section.group(1)):\n",
    "            category = match.group(1).strip()\n",
    "            score = match.group(2).strip().split('/')[0]\n",
    "            description = match.group(3) if match.group(3) else \"\"\n",
    "            try:\n",
    "                score = float(score)\n",
    "            except ValueError:\n",
    "                score = -1\n",
    "            ratings[category] = score\n",
    "            ratings[category + \"_description\"] = description\n",
    "\n",
    "    # Extract summary\n",
    "    summary_match = summary_regex.search(response)\n",
    "    if summary_match:\n",
    "        summary = summary_match.group(1).strip()\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(ratings, index=[0])\n",
    "\n",
    "    # Add Major and Summary columns\n",
    "    df['Major'] = major\n",
    "    df[\"Summary\"] = summary\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:07:01.312315Z",
     "start_time": "2024-08-09T17:07:00.509333Z"
    }
   },
   "outputs": [],
   "source": [
    "path = save_path\n",
    "\n",
    "read_file_list = []\n",
    "df_list = []\n",
    "save_path = f\"{path}\"\n",
    "save_csv_path = f\"{path}\\\\csv_summary\"\n",
    "for filename in os.listdir(save_path):\n",
    "    # Construct absolute path to file\n",
    "    file_path = os.path.join(save_path, filename)\n",
    "    \n",
    "    # Check if the current path is a file and not a directory\n",
    "    if os.path.isfile(file_path) and \".json\" in file_path:\n",
    "        # print(f\"Found file: {filename}\")\n",
    "        # if \"62350081679\" in file_path:\n",
    "        with open(file_path, 'r') as fp:\n",
    "            data = json.load(fp)\n",
    "        #print(data[\"response\"])\n",
    "        \n",
    "        #Skip when response is NULL\n",
    "        if(data[\"response\"]==None):\n",
    "            print(data[\"ID\"][\"identity\"][1]+\"'s response is None\")\n",
    "            rerunEmptyResponse(data[\"ID\"][\"identity\"][1])\n",
    "            with open(file_path, 'r') as fp:\n",
    "                data = json.load(fp)\n",
    "                \n",
    "        decomposed_text = decompose_response(data[\"response\"])\n",
    "        decomposed_text[\"id\"] = data[\"ID\"][\"identity\"][1]\n",
    "        decomposed_text[\"name\"] = data[\"ID\"][\"identity\"][0]\n",
    "        # cols = decomposed_text.columns\n",
    "        # cols.insert(0, cols.pop(cols.index('id')))\n",
    "        # cols.insert(1, cols.pop(cols.index('name')))\n",
    "        df_list.append(decomposed_text)\n",
    "        # read_file_list.append(extract_student_profile(file_path))\n",
    "        # If you need to read the file, you can open it here\n",
    "        # with open(file_path, 'r') as file:\n",
    "        #     content = file.read()\n",
    "        #     # Do something with the content\n",
    "        #     print(content)\n",
    "\n",
    "decomposed_df = pd.concat(df_list, ignore_index=True)\n",
    "cols = decomposed_df.columns.tolist()\n",
    "id_index=cols.index(\"id\")\n",
    "cols = cols[id_index:] +cols[id_index-2:id_index] + cols[:id_index-2]\n",
    "decomposed_df = decomposed_df[cols]\n",
    "print(decomposed_df.columns)\n",
    "# decomposed_df.drop('awards', axis=1, inplace=True)\n",
    "# decomposed_df.drop('awards_description', axis=1, inplace=True)\n",
    "if not os.path.exists(save_csv_path):\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(save_csv_path)\n",
    "decomposed_df.to_csv(f\"{save_csv_path}\\\\summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T14:18:08.692054Z",
     "start_time": "2024-08-09T14:18:08.590664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'Major',\n",
       " 'Summary',\n",
       " 'gpa',\n",
       " 'gpa_description',\n",
       " 'mastery of language',\n",
       " 'mastery of language_description',\n",
       " 'math ability',\n",
       " 'math ability_description',\n",
       " 'specialty core courses',\n",
       " 'specialty core courses_description',\n",
       " 'lab courses',\n",
       " 'lab courses_description',\n",
       " 'capstone/design project',\n",
       " 'capstone/design project_description',\n",
       " 'internship',\n",
       " 'internship_description',\n",
       " 'community service',\n",
       " 'community service_description',\n",
       " 'student clubs',\n",
       " 'student clubs_description',\n",
       " \"major int'l/national competition\",\n",
       " \"major int'l/national competition_description\",\n",
       " 'college of bachelor degree',\n",
       " 'college of bachelor degree_description',\n",
       " 'college of higher degree',\n",
       " 'college of higher degree_description',\n",
       " 'llm pred score',\n",
       " 'llm pred pass']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:07:30.379217Z",
     "start_time": "2024-08-09T17:07:30.289905Z"
    }
   },
   "outputs": [],
   "source": [
    "save_csv_path = \"SAVE_CSV_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:07:32.280279Z",
     "start_time": "2024-08-09T17:07:32.178698Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_df = pd.read_csv(f\"{save_csv_path}\\\\summary.csv\")\n",
    "#encoding = \"ISO-8859-1\" if summary.csv is modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T11:51:22.021441Z",
     "start_time": "2024-08-02T11:51:21.907863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison of two versions' missing categories\n",
    "# \n",
    "# v5_save_csv_path = \"SAVE_CSV_PATH\"\n",
    "# v12_save_csv_path = \"SAVE_CSV_PATH\"\n",
    "# v5_summary_df = pd.read_csv(f\"{v5_save_csv_path}\\\\summary.csv\")\n",
    "# v12_summary_df = pd.read_csv(f\"{v12_save_csv_path}\\\\summary.csv\",encoding = \"ISO-8859-1\")\n",
    "# \n",
    "# v5_lab=v5_summary_df.loc[v5_summary_df['community service']==-1][['id','community service_description']]\n",
    "# v12_lab=v12_summary_df.loc[v12_summary_df['community service']==70][['id','community service','community service_description']]\n",
    "# \n",
    "# diff_lab=v12_lab\n",
    "# diff_lab=diff_lab[~diff_lab['id'].isin(v5_lab['id'])]\n",
    "# v5_summary_df[summary_df['id'].isin(diff_lab['id'])][['id','community service','community service_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:07:43.760067Z",
     "start_time": "2024-08-09T17:07:43.479373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overall score', 'score', 'gpa', 'math ability', 'mastery of language', 'specialty core courses', 'lab courses', 'capstone/design project', 'internship', 'community service', 'student clubs', \"major int'l/national competition\", 'college of bachelor degree']\n"
     ]
    }
   ],
   "source": [
    "def mean_ignore_zeros(series):\n",
    "    non_zero_values = series[(series != 0) & (series != -1)]\n",
    "    if len(non_zero_values) == 0:\n",
    "        return np.nan\n",
    "    return non_zero_values.mean()\n",
    "\n",
    "# Define a function to calculate the mean while ignoring zeros and -1\n",
    "def mean_ignore_zeros_neg_ones(series):\n",
    "    valid_values = series[(series != 0) & (series != -1)]\n",
    "    if len(valid_values) == 0:\n",
    "        return np.nan\n",
    "    return valid_values.mean()\n",
    "\n",
    "def weight_penalty_zeros_neg_ones(series, penaltyRate):\n",
    "    valid_values = series[(series != 0) & (series != -1)]\n",
    "    if len(valid_values) == 0:\n",
    "        return 0\n",
    "    return valid_values.mean()-penaltyRate*(len(series)-len(valid_values))\n",
    "\n",
    "# Function to count zeros and -1 in df_summary\n",
    "def count_zeros_neg_ones(series):\n",
    "    return ((series == 0) | (series == -1)).sum()\n",
    "\n",
    "# Selecting only the numerical columns for mean calculation\n",
    "numerical_cols = ['overall score', 'score', 'gpa', 'math ability', 'mastery of language', 'specialty core courses', 'lab courses', 'capstone/design project', 'internship', 'community service', 'student clubs', \"major int'l/national competition\", 'college of bachelor degree']\n",
    "print(numerical_cols)\n",
    "summary_df['overall score'] = summary_df[numerical_cols[2:-1]].apply(mean_ignore_zeros_neg_ones, axis=1)\n",
    "\n",
    "#calculate score with weight\n",
    "#GPA, math ability, mastery of language, specialty core courses, and lab courses. Weight: 0.125 respectively. \n",
    "penaltyRate=3\n",
    "important_categories_mean=summary_df[numerical_cols[2:7]].apply(weight_penalty_zeros_neg_ones, axis=1, args=(penaltyRate,))\n",
    "#capstone/design project, Internship, Community service, Student clubs, and Major Int'l/National Competition. Weight: 0.075\n",
    "unimportant_categories_mean=summary_df[numerical_cols[7:12]].apply(weight_penalty_zeros_neg_ones, axis=1, args=(penaltyRate,))\n",
    "summary_df['weight score']=important_categories_mean*0.625+unimportant_categories_mean*0.375\n",
    "\n",
    "# Calculate mean evaluations for each student, excluding non-numerical columns\n",
    "grouped = df.groupby('id')[numerical_cols[:1]+numerical_cols[2:]].agg(mean_ignore_zeros_neg_ones)\n",
    "\n",
    "# Rename columns in the grouped dataframe to differentiate from df_summary\n",
    "grouped.columns = [f'mean_{col}' for col in grouped.columns]\n",
    "score = df.groupby('id')['score'].mean().reset_index()\n",
    "# Merge the summary dataframe with the mean evaluations\n",
    "merged_df = pd.merge(summary_df, grouped, on='id', how='outer')\n",
    "merged_df = pd.merge(merged_df, score, on='id', how='outer')\n",
    "merged_df.to_csv(f\"{save_csv_path}\\\\summary_with_prof_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T15:01:45.704425Z",
     "start_time": "2024-08-09T15:01:45.571303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overall score',\n",
       " 'score',\n",
       " 'gpa',\n",
       " 'math ability',\n",
       " 'mastery of language',\n",
       " 'specialty core courses',\n",
       " 'lab courses',\n",
       " 'capstone/design project',\n",
       " 'internship',\n",
       " 'community service',\n",
       " 'student clubs',\n",
       " \"major int'l/national competition\",\n",
       " 'college of bachelor degree']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T17:08:12.997037Z",
     "start_time": "2024-08-09T17:08:12.879239Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_zeros_neg_ones(series):\n",
    "    return ((series == 0) | (series == -1)).sum()\n",
    "abs_errors = pd.DataFrame()\n",
    "\n",
    "for col in numerical_cols[2:]:\n",
    "    summary_col = col.lower()\n",
    "    mean_col = f'mean_{summary_col}'\n",
    "    valid_rows = (merged_df[summary_col] != -1) & (merged_df[summary_col] != 0)\n",
    "    abs_errors[summary_col] = (merged_df.loc[valid_rows, summary_col] - merged_df.loc[valid_rows, mean_col]).abs()\n",
    "\n",
    "# Calculate the MAE for each column\n",
    "mae = abs_errors.mean()\n",
    "zero_neg_one_counts = summary_df[numerical_cols[2:-1]].apply(count_zeros_neg_ones)\n",
    "# Display the MAE\n",
    "print(\"Mean Absolute Error (MAE):\")\n",
    "print(mae)\n",
    "print(\"\\nCount of 0 or -1 in each column of df_summary:\")\n",
    "print(zero_neg_one_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
