{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:36:04.765948Z",
     "start_time": "2024-08-21T21:36:04.761961Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze OCR and Other Read Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:36:07.132049Z",
     "start_time": "2024-08-21T21:36:07.127628Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "important_keys = [\"Education Background\", \"Awards and Professional Qualifications\", \n",
    "                  \"Publications\", \"English Language Proficiency\", \"Proposed Research Plan / Vision Statement\", \n",
    "                  \"CV\", \"Extracurricular Activities / Volunteer Work\", \"Taken Courses\", \"Reference Report\"]\n",
    "\n",
    "def read_json_to_dict(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extract only the important keys, handling missing keys with None\n",
    "    return {key: data.get(key, None) for key in important_keys}\n",
    "\n",
    "def process_json_files(directory):\n",
    "    data_list = []\n",
    "    \n",
    "    # Iterate through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            row_data = read_json_to_dict(filepath)\n",
    "            row_data.update({'id': filename.split('.')[0]})\n",
    "            data_list.append(row_data)\n",
    "    \n",
    "    # Convert list of dicts to DataFrame\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:37:39.864791Z",
     "start_time": "2024-08-21T21:37:39.841157Z"
    }
   },
   "outputs": [],
   "source": [
    "profile_num=[7,8,10]\n",
    "version_num=12\n",
    "\n",
    "dataList=[]\n",
    "for num in profile_num:\n",
    "    print(\"Round \"+str(num))\n",
    "    directory_path = f\"\\\\csv_summary\"#Replace with real directory path\n",
    "    tempData=pd.read_csv(f\"{directory_path}\\\\summary_with_prof_eval.csv\")\n",
    "    print(len(tempData))\n",
    "    dataList.append(tempData)\n",
    "\n",
    "data=pd.concat(dataList)\n",
    "data=data.reset_index(drop=True)\n",
    "data['llm pred pass'] = data['llm pred pass'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:37:43.666321Z",
     "start_time": "2024-08-21T21:37:43.662463Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop('mean_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T21:37:46.767293Z",
     "start_time": "2024-08-21T21:37:46.749612Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_zeros_neg_ones(series):\n",
    "    return ((series == 0) | (series == -1)).sum()\n",
    "\n",
    "numerical_cols = ['overall score', 'gpa', 'math ability', 'mastery of language', 'specialty core courses', 'lab courses', 'capstone/design project', 'internship', 'community service', 'student clubs', \"major int'l/national competition\", 'college of bachelor degree']\n",
    "abs_errors = pd.DataFrame()\n",
    "\n",
    "for col in numerical_cols[1:]:\n",
    "    summary_col = col.lower()\n",
    "    mean_col = f'mean_{summary_col}'\n",
    "    valid_rows = (data[summary_col] != -1) & (data[summary_col] != 0)\n",
    "    abs_errors[summary_col] = (data.loc[valid_rows, summary_col] - data.loc[valid_rows, mean_col]).abs()\n",
    "\n",
    "valid_rows = (data['weight score'] != -1) & (data['weight score'] != 0)\n",
    "abs_errors['overall score']=(data.loc[valid_rows, 'weight score'] - data.loc[valid_rows, 'mean_overall score']).abs()\n",
    "# Calculate the MAE for each column\n",
    "mae = abs_errors.mean()\n",
    "zero_neg_one_counts = data[numerical_cols[2:-1]].apply(count_zeros_neg_ones)\n",
    "# Display the MAE\n",
    "print(\"Mean Absolute Error (MAE):\")\n",
    "print(mae)\n",
    "print(\"\\nCount of 0 or -1 in each column of df_summary:\")\n",
    "print(zero_neg_one_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.017525Z",
     "start_time": "2024-08-12T09:14:51.011079Z"
    }
   },
   "outputs": [],
   "source": [
    "data[[f'mean_{c}'for c in numerical_cols]].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.074460Z",
     "start_time": "2024-08-12T09:14:51.069614Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_data = data[data.columns[~data.columns.str.contains('description')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.411825Z",
     "start_time": "2024-08-12T09:14:51.376321Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.420357Z",
     "start_time": "2024-08-12T09:14:51.414820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                               0.000000\n",
       "name                                             0.000000\n",
       "Major                                            0.000000\n",
       "Summary                                          0.000000\n",
       "gpa                                              0.000000\n",
       "gpa_description                                  0.000000\n",
       "mastery of language                              0.000000\n",
       "mastery of language_description                  0.000000\n",
       "math ability                                     0.000000\n",
       "math ability_description                         0.000000\n",
       "specialty core courses                           0.000000\n",
       "specialty core courses_description               0.000000\n",
       "lab courses                                      0.000000\n",
       "lab courses_description                          0.000000\n",
       "capstone/design project                          0.000000\n",
       "capstone/design project_description              0.000000\n",
       "internship                                       0.000000\n",
       "internship_description                           0.651466\n",
       "community service                                0.000000\n",
       "community service_description                    0.000000\n",
       "student clubs                                    0.000000\n",
       "student clubs_description                        0.325733\n",
       "major int'l/national competition                 0.000000\n",
       "major int'l/national competition_description     0.325733\n",
       "college of bachelor degree                       0.000000\n",
       "college of bachelor degree_description           0.000000\n",
       "college of higher degree                        66.123779\n",
       "college of higher degree_description            66.449511\n",
       "llm pred score                                   0.000000\n",
       "llm pred pass                                    0.000000\n",
       "overall score                                    0.000000\n",
       "weight score                                     0.000000\n",
       "mean_overall score                               0.000000\n",
       "mean_gpa                                         0.000000\n",
       "mean_math ability                                0.000000\n",
       "mean_mastery of language                         0.000000\n",
       "mean_specialty core courses                      0.000000\n",
       "mean_lab courses                                 0.000000\n",
       "mean_capstone/design project                     0.000000\n",
       "mean_internship                                  0.000000\n",
       "mean_community service                           0.000000\n",
       "mean_student clubs                               0.000000\n",
       "mean_major int'l/national competition            0.000000\n",
       "mean_college of bachelor degree                  0.000000\n",
       "score                                            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rate = data.isna().mean() * 100\n",
    "nan_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.570372Z",
     "start_time": "2024-08-12T09:14:51.567450Z"
    }
   },
   "outputs": [],
   "source": [
    "#merged_data = pd.merge(data, data_excel[[\"Pass pre-shortlist or not\", \"Application No.\"]], left_on='id', right_on='Application No.')\n",
    "#merged_data['Passed'] = merged_data['Pass pre-shortlist or not']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.630591Z",
     "start_time": "2024-08-12T09:14:51.625369Z"
    }
   },
   "outputs": [],
   "source": [
    "# new_merged_data = merged_data.dropna()\n",
    "data['Passed'] = data['score'].apply(lambda x: 'passed' if x > 0 else 'unpassed')\n",
    "passed_students = data[data['score'] >0]\n",
    "unpassed_students = data[data['score'] <=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:51.835982Z",
     "start_time": "2024-08-12T09:14:51.742451Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), facecolor=\"white\")  # Set the figure size for better visibility\n",
    "palette = {'passed': 'blue', 'unpassed': 'orange'}\n",
    "barplot=sns.countplot(data=data, x='Passed', palette='pastel')\n",
    "plt.title('Count of Passed vs. Unpassed Students',  fontsize=18)\n",
    "plt.xlabel('Status',  fontsize=14)\n",
    "plt.ylabel('Number of Students', fontsize=14)\n",
    "plt.xticks(fontsize=14)  # Larger x-axis tick labels\n",
    "for spine in barplot.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(0.5)\n",
    "# plt.savefig('./figure/Total_passed_student.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:52.145460Z",
     "start_time": "2024-08-12T09:14:51.909495Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Good_univeristy'] = data['college of bachelor degree'].dropna()>=90\n",
    "print(data['Good_univeristy'].mean()*100)\n",
    "cleaned_data = data.dropna(subset=['college of bachelor degree'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=data, x='Good_univeristy', y='gpa', palette='coolwarm')\n",
    "plt.title('Comparison of GPA by University Status', fontsize=18)\n",
    "plt.xlabel('Is Good University?', fontsize=14)\n",
    "plt.ylabel('Average GPA', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylim(40, 100)\n",
    "plt.show()\n",
    "\n",
    "data['Good_english'] = data['mastery of language'].dropna()>=90\n",
    "   \n",
    "cleaned_data = data.dropna(subset=['mastery of language'])\n",
    "print(data['Good_english'].mean()*100)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=data, x='Good_english', y='gpa', palette='coolwarm')\n",
    "plt.title('Comparison of GPA by University English Capability', fontsize=18)\n",
    "plt.xlabel('Is Good English?', fontsize=14)\n",
    "plt.ylabel('Average GPA', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylim(30, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:52.279964Z",
     "start_time": "2024-08-12T09:14:52.146455Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_data = data[data.columns[~data.columns.str.contains('description')]]\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "contains_keyword = data['mastery of language_description'].str.contains(\"institution\", na=False)\n",
    "data['study abroad'] = pd.Categorical(contains_keyword, categories=[True, False], ordered=True)\n",
    "\n",
    "# Now calculate the pass rates\n",
    "study_abroad_pass_rate = data[data['study abroad'] == True]['Passed'].eq('passed').mean()\n",
    "non_study_abroad_pass_rate = data[data['study abroad'] == False]['Passed'].eq('passed').mean()\n",
    "\n",
    "# Set the display option for columns\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=['Study Abroad', 'Non Study Abroad'], y=[study_abroad_pass_rate, non_study_abroad_pass_rate], palette='coolwarm')\n",
    "plt.title('Pass Rate Comparison: Study Abroad vs. Non Study Abroad Students')\n",
    "plt.ylabel('Pass Rate')\n",
    "plt.ylim(0, 1)  # Set y-axis limit to ensure values are between 0 and 1\n",
    "plt.show()\n",
    "\n",
    "# study_abroad_pass_rate = (merged_data.loc[contains_keyword, 'Passed'] == 'passed').mean()\n",
    "# non_study_abroad_pass_rate = (merged_data.loc[~contains_keyword, 'Passed'] == 'passed').mean()\n",
    "\n",
    "# # Create a bar plot\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.barplot(x=['Study Abroad', 'Non Study Abroad'], y=[study_abroad_pass_rate, non_study_abroad_pass_rate])\n",
    "# plt.title('Pass Rate Comparison: Study Abroad vs. Non Study Abroad Students')\n",
    "# plt.ylabel('Pass Rate')\n",
    "# plt.ylim(0, 1)  # Set y-axis limit to ensure values are between 0 and 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:52.690812Z",
     "start_time": "2024-08-12T09:14:52.375387Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_ignore_zeros_neg_ones(series):\n",
    "    valid_values = series[(series != 0) & (series != -1)]\n",
    "    if len(valid_values) == 0:\n",
    "        return np.nan\n",
    "    return valid_values.mean()\n",
    "\n",
    "pred_columnIndex=['id', 'name', 'Major', 'gpa', 'math ability','mastery of language', 'specialty core courses', 'lab courses',\n",
    "           'capstone/design project', 'internship', 'community service',\n",
    "           'student clubs', 'major int\\'l/national competition', 'college of bachelor degree',\n",
    "             'college of higher degree', 'llm pred score', 'llm pred pass',\n",
    "             'overall score', 'weight score','score', 'Passed', 'Summary', 'Good_univeristy', 'Good_english', 'study abroad']\n",
    "not_pred_columnIndex=['id', 'gpa', 'math ability', 'mastery of language',\n",
    "                      'specialty core courses', 'lab courses', 'capstone/design project',\n",
    "                      'internship', 'community service', 'student clubs',\n",
    "                      'major int\\'l/national competition', 'college of bachelor degree',\n",
    "                      'overall score', 'Passed']\n",
    "\n",
    "merged_data = data\n",
    "# merged_data['Passed'] = pd.Categorical(merged_data['Passed'], categories=['passed', 'unpassed'])\n",
    "merged_data_all = merged_data[merged_data.columns[~merged_data.columns.str.contains('description')]]\n",
    "merged_data_pred = merged_data_all[merged_data_all.columns[~merged_data_all.columns.str.contains('mean')]]\n",
    "merged_data_pred=merged_data_pred.loc[:,pred_columnIndex]\n",
    "merged_data_not_pred = merged_data_all[['id']+merged_data_all.columns[merged_data_all.columns.str.contains('mean')].to_list()+['Passed']]\n",
    "print(merged_data_not_pred.columns)\n",
    "merged_data_not_pred.columns = [i.replace('mean_','')for i in merged_data_not_pred.columns]\n",
    "merged_data_not_pred=merged_data_not_pred.loc[:,not_pred_columnIndex]\n",
    "merged_data_pred_score = merged_data_pred.loc[:, ~merged_data_pred.columns.str.contains('description', case=False)]\n",
    "# merged_data_score = merged_data_score.drop([\"id\",\"name\",\"Major\",\"Summary\",\"Pass pre-shortlist or not\"], axis=1)\n",
    "merged_data_pred_score = merged_data_pred_score.drop([\"Major\",\"name\",\"Summary\",\"Good_univeristy\",\"Good_english\",'study abroad','score'], axis=1)\n",
    "# merged_data_pred_score=merged_data_pred_score.loc[:,columnIndex] #reorder column\n",
    "# print(merged_data_pred_score.info(True))\n",
    "# merged_data_score[\"Total Average\"] = merged_data_score.drop(['Passed'], axis=1).mean(axis=1)\n",
    "# Descriptive statistics for numeric data\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(merged_data_not_pred.groupby('Passed'))\n",
    "\n",
    "# mean_values = merged_data_pred_score.groupby('Passed').agg(mean_ignore_zeros_neg_ones).reset_index()\n",
    "# melted_df = pd.melt(mean_values, id_vars=['Passed'], value_vars=merged_data_pred_score.drop(['Passed', 'id', 'college of higher degree','llm pred pass', 'llm pred score', 'overall score'], axis=1).columns.to_list(),\n",
    "#                     var_name='Metric', value_name='Mean Value')\n",
    "mean_values = merged_data_not_pred.groupby('Passed').agg(mean_ignore_zeros_neg_ones).reset_index()\n",
    "melted_df = pd.melt(mean_values, id_vars=['Passed'], value_vars=merged_data_not_pred.drop(['Passed', 'id'], axis=1).columns.to_list(),\n",
    "                                        var_name='Metric', value_name='Mean Value')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "barplot = sns.barplot(data=melted_df, x='Metric', y='Mean Value', hue='Passed')\n",
    "plt.title('Comparison of Mean Values for Passed vs Unpassed Students')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.xlabel('Variables')\n",
    "# plt.xticks(rotation=45)\n",
    "plt.legend(title='Passed Status')\n",
    "plt.ylim(65, 95)\n",
    "barplot.set_xticklabels(barplot.get_xticklabels(), rotation=20, horizontalalignment='right')\n",
    "\n",
    "\n",
    "plt.title('Comparison of Mean Values for Passed vs Unpassed Students', fontsize=24)\n",
    "plt.xlabel('', fontsize=20)  # Larger x-axis label\n",
    "plt.ylabel('', fontsize=20)  # Larger y-axis label\n",
    "plt.xticks(fontsize=20)  # Larger x-axis tick labels\n",
    "plt.yticks(fontsize=20)  # Larger y-axis tick labels\n",
    "plt.legend(title='Passed Status', title_fontsize='13', fontsize='12',loc='upper left')\n",
    "\n",
    "barplot.set_facecolor('white')\n",
    "for spine in barplot.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(0.5)\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figure/Total_real_meanvalue_pvsunp.jpg')\n",
    "plt.show()\n",
    "\n",
    "# Histograms for scores\n",
    "\n",
    "\n",
    "\n",
    "# # Box plots for attendance\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.boxplot(x='Passed', y='Attendance', data=df)\n",
    "# plt.title('Attendance by Pass Status')\n",
    "# plt.show()\n",
    "\n",
    "# # Categorical data analysis\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.countplot(x='Department', hue='Passed', data=df)\n",
    "# plt.title('Department Wise Pass Status')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:52.968475Z",
     "start_time": "2024-08-12T09:14:52.838766Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "### How to select who pass\n",
    "# 1. Mean of Rating - \"overall score\"\n",
    "# 2. GPT Overall Score - \"llm pred score\"\n",
    "# 3. GPT pass or not - \"llm pred pass\"\n",
    "# 4. Weight score - \"weight score\"\n",
    "selected_column = \"weight score\"\n",
    "\n",
    "threshold_index = int(len(merged_data_pred_score) * 0.75)\n",
    "# threshold_index= 270\n",
    "# Sort the DataFrame by 'score' in descending order\n",
    "sorted_scores = merged_data_pred_score.sort_values(by=selected_column, ascending=False)\n",
    "\n",
    "# Get the score at the threshold index\n",
    "threshold_score = sorted_scores.iloc[threshold_index][selected_column]\n",
    "# print(threshold_score)\n",
    "# threshold = merged_data_pred_score[selected_column].quantile(2/3)\n",
    "# Set the 'overall score' for the top 2/3 students\n",
    "merged_data_pred['pred_status'] = merged_data_pred.apply(\n",
    "    lambda row: row[selected_column] >= threshold_score, axis=1\n",
    ")\n",
    "merged_data_pred['status_binary'] = merged_data_pred['score'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Calculate accuracy\n",
    "#accuracy = accuracy_score(merged_data_pred['status_binary'], merged_data_pred['llm pred pass'])\n",
    "accuracy = accuracy_score(merged_data_pred['status_binary'], merged_data_pred['pred_status'])\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Calculate recall\n",
    "#recall = recall_score(merged_data_pred['status_binary'], merged_data_pred['llm pred pass'])\n",
    "recall = recall_score(merged_data_pred['status_binary'], merged_data_pred['pred_status'])\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "#cm = confusion_matrix(merged_data_pred['status_binary'], merged_data_pred['llm pred pass'])\n",
    "cm = confusion_matrix(merged_data_pred['status_binary'], merged_data_pred['pred_status'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['unpass', 'pass'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "# plt.savefig('./figure/Total_v12_Confusion_Matrix.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:53.296339Z",
     "start_time": "2024-08-12T09:14:53.286339Z"
    }
   },
   "outputs": [],
   "source": [
    "#Detail of students with different result\n",
    "ind=0\n",
    "while ind < len(merged_data_pred):\n",
    "    if merged_data_pred.loc[ind, 'status_binary'] != merged_data_pred.loc[ind,'pred_status']:\n",
    "        #print(\"Student ID: \"+str(merged_data_not_pred.loc[ind, 'id'])+  \". Mean overall score: \"+str(merged_data_not_pred.loc[ind, 'overall score'])+\", predict score: \"+str(merged_data_pred.loc[ind, 'overall score']))\n",
    "        print(\"Student ID: \"+str(merged_data_not_pred.loc[ind, 'id'])+  \". True-Pred: \"+str(merged_data_not_pred.loc[ind, 'overall score']-merged_data_pred.loc[ind, 'overall score']))\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:53.759347Z",
     "start_time": "2024-08-12T09:14:53.735997Z"
    }
   },
   "outputs": [],
   "source": [
    "mismatch=merged_data_all[merged_data_pred['status_binary'] != merged_data_pred['pred_status']]\n",
    "# mismatch['False Pass']= mismatch['pred_status']==True\n",
    "mismatch['Dif To Threshold']=mismatch[selected_column]-threshold_score\n",
    "mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:55.929619Z",
     "start_time": "2024-08-12T09:14:54.045600Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 6, figsize=(45, 12))  # Adjusted figsize for better fit\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "used_data = merged_data_not_pred \n",
    "# merged_data_pred_score, merged_data_not_pred \n",
    "# Iterate over each column (excluding 'Passed' which is used for hue)\n",
    "for i, col in enumerate([c for c in ['gpa', 'math ability','mastery of language', 'specialty core courses', 'lab courses',\n",
    "                                                               'capstone/design project', 'internship', 'community service',\n",
    "                                                               'student clubs', 'major int\\'l/national competition', 'college of bachelor degree', 'overall score']]):\n",
    "\n",
    "    # Create histogram in the specified subplot\n",
    "    ax = axes[i]\n",
    "    filtered_data = used_data[(used_data[col] != 0) & (used_data[col] != -1)]\n",
    "    sns.histplot(data=filtered_data, x=col, hue='Passed', element='step', bins=10, ax=ax, hue_order=['passed','unpassed'])\n",
    "    if col == \"major int'l/national competition\":\n",
    "        col = 'competition'\n",
    "    ax.set_xlabel(col, fontsize=40)\n",
    "    ax.set_ylabel('', fontsize=20)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    ax.set_facecolor('white')\n",
    "    # Customize the legend\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.set_title('Pass Status', prop={'size': 24})\n",
    "        leg.set_frame_on(True)\n",
    "        # leg.set_bbox_to_anchor((1,1))  # Adjust position of legend\n",
    "        for text in leg.get_texts():\n",
    "            text.set_fontsize('20')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "\n",
    "# plt.legend(loc='upper left')\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figure/Total_pred_summary.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T09:14:55.952985Z",
     "start_time": "2024-08-12T09:14:55.949294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gpa', 'math ability', 'mastery of language',\n",
       "       'specialty core courses', 'lab courses', 'capstone/design project',\n",
       "       'internship', 'community service', 'student clubs',\n",
       "       'major int'l/national competition', 'college of bachelor degree',\n",
       "       'overall score', 'Passed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_not_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:31:56.495217Z",
     "start_time": "2024-08-12T13:31:55.334177Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_for_heatmap = merged_data_not_pred.copy(deep=True)\n",
    "# data_for_heatmap['Passed'] = data_for_heatmap['Passed'] == \"passed\"\n",
    "# data_for_heatmap=data_for_heatmap.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "data_for_heatmap = merged_data_pred.copy(deep=True)\n",
    "data_for_heatmap['Passed'] = data_for_heatmap['Passed'] == \"passed\"\n",
    "\n",
    "data_for_heatmap = data_for_heatmap.drop([\n",
    "    'id', 'name', 'Major', 'Summary', 'college of higher degree',\n",
    "    'Good_univeristy', 'Good_english', 'study abroad', 'score',\n",
    "    'llm pred pass', 'status_binary', 'weight score', 'llm pred score',\n",
    "    'pred_status'\n",
    "], axis=1)\n",
    "\n",
    "cols = data_for_heatmap.columns.tolist()\n",
    "data_for_heatmap = data_for_heatmap[cols]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data_for_heatmap.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "# passed_corr = correlation_matrix[['Passed']].drop('Passed')\n",
    "# heatmap = sns.heatmap(passed_corr, annot=True, fmt=\".2f\", cmap='YlGnBu', ax=ax, annot_kws={\"fontsize\":20})\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='YlGnBu', ax=ax, annot_kws={\"fontsize\":20})\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "# Customize tick labels for better readability\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figure/Total_pred_heatmap.jpg')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:35:16.799741Z",
     "start_time": "2024-08-12T13:35:15.378526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a 3x5 grid of subplots for box plots\n",
    "fig, axes = plt.subplots(2, 6, figsize=(45, 12))  # Adjusted figsize for better fit\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "# used_data = merged_data_not_pred\n",
    "used_data = merged_data_pred_score\n",
    "# merged_data_not_pred, merged_data_pred_score\n",
    "filtered_data = used_data[(used_data != 0) & (used_data != -1)].dropna()\n",
    "# print(filtered_data)\n",
    "# Plotting box plots for each numerical column, excluding 'Passed' which is used for hue\n",
    "# for i, col in enumerate([c for c in merged_data_pred_score.columns if c not in ['Passed', 'id','score','referees feedbacks', 'college of higher degree']]):\n",
    "for i, col in enumerate([c for c in used_data.columns if c not in ['Passed', 'id','score','referees feedbacks', 'college of higher degree']]):\n",
    "   \n",
    "    ax = axes[i]\n",
    "    filtered_data = used_data[(used_data[col] != 0) & (used_data[col] != -1)]\n",
    "    sns.boxplot(data=filtered_data, x='Passed', y=col, ax=ax, palette=\"Blues\", order=['passed','unpassed'])\n",
    "    if col == \"major int'l/national competition\":\n",
    "        col = 'competition'\n",
    "    ax.set_xlabel(col, fontsize=40)\n",
    "    ax.set_ylabel('', fontsize=20)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    # Customize the legend\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.set_title('Pass Status', prop={'size': 24})\n",
    "        leg.set_frame_on(True)\n",
    "        # leg.set_bbox_to_anchor((1, 1))  # Adjust position of legend\n",
    "        for text in leg.get_texts():\n",
    "            text.set_fontsize('20')\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./figure/pred_boxplot.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:47:00.490617Z",
     "start_time": "2024-08-12T13:46:57.052850Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5, figsize=(30, 18))  # Adjusted figsize for better fit\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "real_data = merged_data_not_pred\n",
    "pred_data = merged_data_pred_score\n",
    "# merged_data_not_pred, merged_data_pred_score\n",
    "exclude_cols = ['Passed', 'id','score','referees feedbacks', 'college of higher degree',\"llm pred score\",\"llm pred pass\",\"weight score\"]\n",
    "diff_data = pd.DataFrame()\n",
    "for col in pred_data.columns:\n",
    "    if col not in exclude_cols:\n",
    "        # valid_indices = (real_data[col] != 0) & (real_data[col] != -1) & (pred_data[col] != 0) & (pred_data[col] != -1)\n",
    "        valid_indices = (real_data[col] != 0) & (real_data[col] != -1) \n",
    "        diff_data[col] = real_data.loc[valid_indices, col] - pred_data.loc[valid_indices, col]\n",
    "        # diff_data[col] = real_data.loc[:, col] - pred_data.loc[:, col]\n",
    "# Plotting box plots for each numerical column, excluding 'Passed' which is used for hue\n",
    "# for i, col in enumerate([c for c in merged_data_pred_score.columns if c not in ['Passed', 'id','score','referees feedbacks', 'college of higher degree']]):\n",
    "for i, col in enumerate(diff_data.columns):\n",
    "    sns.histplot(diff_data[col].dropna().abs(), bins=8, kde=True, ax=axes[i], color=\"lightblue\")\n",
    "    axes[i].set_xlabel(col, fontsize=20)\n",
    "    axes[i].set_ylabel('Num of Students', fontsize=20)\n",
    "    axes[i].tick_params(labelsize=20)\n",
    "    axes[i].yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    axes[i].set_ylim(0, 320)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figure/Total_v12_diff_boxplot.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
